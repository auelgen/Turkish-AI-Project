{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pytextrank\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import joblib\n",
    "\n",
    "def veritabani():\n",
    "    try:\n",
    "        dt = psycopg2.connect(database=\"postgres\",\n",
    "                              user=\"postgres\",\n",
    "                              host='localhost',\n",
    "                              password=\"12345\",\n",
    "                              port=5432)\n",
    "        cr = dt.cursor()\n",
    "        cr.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS yapay_zeka (\n",
    "            metin_id SERIAL PRIMARY KEY,\n",
    "            ana_konu VARCHAR(1000),\n",
    "            alt_konu VARCHAR(1000),\n",
    "            output TEXT\n",
    "        );\n",
    "        \"\"\")\n",
    "        dt.commit()\n",
    "        return dt, cr\n",
    "    except Exception as e:\n",
    "        print(\"Veritabani hatasi:\", e)\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    stop_words = set(stopwords.words(\"turkish\"))\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "class Siniflandirma:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.model = LinearSVC()\n",
    "\n",
    "    def egitim(self):\n",
    "        data = pd.read_excel(self.data_path)\n",
    "        data['metin'] = data['metin'].apply(preprocess_text)\n",
    "        data_train, data_test = train_test_split(data, test_size=0.2, stratify=data['kategori'])\n",
    "        x_train = self.vectorizer.fit_transform(data_train['metin'])\n",
    "        x_test = self.vectorizer.transform(data_test['metin'])\n",
    "        self.model.fit(x_train, data_train['kategori'])\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        print(\"Model Performansi:\")\n",
    "        print(classification_report(data_test['kategori'], y_pred))\n",
    "        # Model ve öznitelik çıkarıcıyı kaydet\n",
    "        joblib.dump(self.model, \"model.pkl\")\n",
    "        joblib.dump(self.vectorizer, \"vectorizer.pkl\")\n",
    "\n",
    "    def tahmin(self, metin):\n",
    "        metin = preprocess_text(metin)\n",
    "        vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "        model = joblib.load(\"model.pkl\")\n",
    "        x_new = vectorizer.transform([metin])\n",
    "        return model.predict(x_new)[0]\n",
    "\n",
    "def load_nlp_model():\n",
    "    nlp = spacy.load(\"tr_core_news_md\")\n",
    "    nlp.add_pipe(\"textrank\")\n",
    "    return nlp\n",
    "\n",
    "def ozetle(metin, nlp_model):\n",
    "    doc = nlp_model(metin)\n",
    "    return doc._.phrases[0].text if doc._.phrases else \"Konu bulunamadi\"\n",
    "\n",
    "def aramamotoru(se):\n",
    "    url = f\"https://google.com/search?q={se}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "    output = requests.get(url, headers=headers)\n",
    "    if output.status_code == 200:\n",
    "        soup = BeautifulSoup(output.text, \"html.parser\")\n",
    "        sonuclar = []\n",
    "        for result in soup.select(\".tF2Cxc\"):\n",
    "            baslik = result.select_one(\"h3\").text if result.select_one(\"h3\") else \"Başlik bulunamadi\"\n",
    "            snippet = result.select_one(\".VwiC3b\").text if result.select_one(\".VwiC3b\") else \"Aciklama bulunamadi\"\n",
    "            sonuclar.append(f\"Baslik: {baslik}\\nSnippet: {snippet}\\n\")\n",
    "        return sonuclar\n",
    "    else:\n",
    "        print(f\"Hata oluştu: {output.status_code}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    dt, cr = veritabani()\n",
    "    if not dt or not cr:\n",
    "        print(\"Veritabanina hatasi.\")\n",
    "        return\n",
    "\n",
    "    data_path = \"veri.xlsx\"\n",
    "    classifier = Siniflandirma(data_path)\n",
    "    classifier.egitim()\n",
    "\n",
    "    nlp_model = load_nlp_model()\n",
    "\n",
    "    while True:\n",
    "        ara = input(\"Aramak istediğiniz sorguyu girin (Cikis için 'q'): \").strip()\n",
    "        if ara.lower() == \"q\":\n",
    "            print(\"Program sonlandiriliyor.\")\n",
    "            break\n",
    "        elif not ara:\n",
    "            print(\"Boş bir sorgu girdiniz. Lütfen tekrar deneyin.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ana_konu = ozetle(ara, nlp_model)\n",
    "            print(f\"Ana Konu: {ana_konu}\")\n",
    "            alt_konu = classifier.tahmin(ana_konu)\n",
    "            print(f\"Alt Konu: {alt_konu}\")\n",
    "\n",
    "            sonuc = f\"{ana_konu} {alt_konu}\"\n",
    "            output = aramamotoru(sonuc)\n",
    "            output_text = \" | \".join(output)[:1000]\n",
    "\n",
    "            print(output_text)\n",
    "            cr.execute(\n",
    "                \"INSERT INTO yapay_zeka (ana_konu, alt_konu, output) VALUES (%s, %s, %s)\",\n",
    "                (ana_konu, alt_konu, output_text)\n",
    "            )\n",
    "            dt.commit()\n",
    "        except Exception as e:\n",
    "            print(\"Hata:\", e)\n",
    "            dt.rollback()\n",
    "\n",
    "    cr.close()\n",
    "    dt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
